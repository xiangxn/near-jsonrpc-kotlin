/**
 *
 * Please note:
 * This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * Do not edit this file manually.
 *
 */

@file:Suppress(
    "ArrayInDataClass",
    "EnumEntryName",
    "RemoveRedundantQualifierName",
    "UnusedImport"
)

package org.openapitools.client.models

import org.openapitools.client.models.ChunkDistributionNetworkConfig
import org.openapitools.client.models.CloudArchivalReaderConfig
import org.openapitools.client.models.CloudArchivalWriterConfig
import org.openapitools.client.models.EpochSyncConfig
import org.openapitools.client.models.GCConfig
import org.openapitools.client.models.LogSummaryStyle
import org.openapitools.client.models.ProtocolVersionCheckConfig
import org.openapitools.client.models.StateSyncConfig
import org.openapitools.client.models.TrackedShardsConfig
import org.openapitools.client.models.Version

import com.squareup.moshi.Json
import com.squareup.moshi.JsonClass

/**
 * ClientConfig where some fields can be updated at runtime.
 *
 * @param archive Not clear old data, set `true` for archive nodes.
 * @param blockFetchHorizon Horizon at which instead of fetching block, fetch full state.
 * @param blockHeaderFetchHorizon Behind this horizon header fetch kicks in.
 * @param blockProductionTrackingDelay Duration to check for producing / skipping block.
 * @param catchupStepPeriod Time between check to perform catchup.
 * @param chainId Chain id for status.
 * @param chunkRequestRetryPeriod Time between checking to re-request chunks.
 * @param chunkValidationThreads Number of threads for ChunkValidationActor pool.
 * @param chunkWaitMult Multiplier for the wait time for all chunks to be received.
 * @param clientBackgroundMigrationThreads Number of threads to execute background migration work in client.
 * @param doomslugStepPeriod Time between running doomslug timer.
 * @param enableMultilineLogging 
 * @param enableStatisticsExport Re-export storage layer statistics as prometheus metrics.
 * @param epochLength Epoch length.
 * @param epochSync Options for epoch sync.
 * @param expectedShutdown Graceful shutdown at expected block height.
 * @param gc Garbage collection configuration.
 * @param headerSyncExpectedHeightPerSecond Expected increase of header head height per second during header sync
 * @param headerSyncInitialTimeout How much time to wait after initial header sync
 * @param headerSyncProgressTimeout How much time to wait after some progress is made in header sync
 * @param headerSyncStallBanTimeout How much time to wait before banning a peer in header sync if sync is too slow
 * @param logSummaryPeriod Period between logging summary information.
 * @param logSummaryStyle Enable coloring of the logs
 * @param maxBlockProductionDelay Maximum wait for approvals before producing block.
 * @param maxBlockWaitDelay Maximum duration before skipping given height.
 * @param minBlockProductionDelay Minimum duration before producing block.
 * @param minNumPeers Minimum number of peers to start syncing.
 * @param numBlockProducerSeats Number of block producer seats
 * @param orphanStateWitnessMaxSize Maximum size of state witnesses in the OrphanStateWitnessPool.  We keep only orphan witnesses which are smaller than this size. This limits the maximum memory usage of OrphanStateWitnessPool.
 * @param orphanStateWitnessPoolSize OrphanStateWitnessPool keeps instances of ChunkStateWitness which can't be processed because the previous block isn't available. The witnesses wait in the pool until the required block appears. This variable controls how many witnesses can be stored in the pool.
 * @param produceChunkAddTransactionsTimeLimit Limit the time of adding transactions to a chunk. A node produces a chunk by adding transactions from the transaction pool until some limit is reached. This time limit ensures that adding transactions won't take longer than the specified duration, which helps to produce the chunk quickly.
 * @param produceEmptyBlocks Produce empty blocks, use `false` for testing.
 * @param protocolVersionCheck Determines whether client should exit if the protocol version is not supported for the next or next next epoch.
 * @param reshardingConfig 
 * @param saveInvalidWitnesses Save observed instances of invalid ChunkStateWitness to the database in DBCol::InvalidChunkStateWitnesses. Saving invalid witnesses is useful for analysis and debugging. This option can cause extra load on the database and is not recommended for production use.
 * @param saveLatestWitnesses Save observed instances of ChunkStateWitness to the database in DBCol::LatestChunkStateWitnesses. Saving the latest witnesses is useful for analysis and debugging. This option can cause extra load on the database and is not recommended for production use.
 * @param saveTrieChanges save_trie_changes should be set to true iff - archive if false - non-archival nodes need trie changes to perform garbage collection - archive is true, cold_store is configured and migration to split_storage is finished - node working in split storage mode needs trie changes in order to do garbage collection on hot.
 * @param saveTxOutcomes Whether to persist transaction outcomes to disk or not.
 * @param skipSyncWait Skip waiting for sync (for testing or single node testnet).
 * @param stateRequestServerThreads Number of threads for StateRequestActor pool.
 * @param stateRequestThrottlePeriod Number of seconds between state requests for view client. Throttling window for state requests (headers and parts).
 * @param stateRequestsPerThrottlePeriod Maximum number of state requests served per throttle period
 * @param stateSync Options for syncing state.
 * @param stateSyncEnabled Whether to use the State Sync mechanism. If disabled, the node will do Block Sync instead of State Sync.
 * @param stateSyncExternalBackoff Additional waiting period after a failed request to external storage
 * @param stateSyncExternalTimeout How long to wait for a response from centralized state sync
 * @param stateSyncP2pTimeout How long to wait for a response from p2p state sync
 * @param stateSyncRetryBackoff How long to wait after a failed state sync request
 * @param syncCheckPeriod How often to check that we are not out of sync.
 * @param syncHeightThreshold Sync height threshold: below this difference in height don't start syncing.
 * @param syncMaxBlockRequests Maximum number of block requests to send to peers to sync
 * @param syncStepPeriod While syncing, how long to check for each step.
 * @param trackedShardsConfig 
 * @param transactionRequestHandlerThreads 
 * @param ttlAccountIdRouter Time to persist Accounts Id in the router without removing them.
 * @param txRoutingHeightHorizon If the node is not a chunk producer within that many blocks, then route to upcoming chunk producers.
 * @param version Version of the binary.
 * @param viewClientThreads Number of threads for ViewClientActor pool.
 * @param chunkDistributionNetwork 
 * @param cloudArchivalReader 
 * @param cloudArchivalWriter 
 * @param maxGasBurntView 
 * @param rpcAddr Listening rpc port for status.
 * @param transactionPoolSizeLimit Limit of the size of per-shard transaction pool measured in bytes. If not set, the size will be unbounded.
 * @param trieViewerStateSizeLimit Upper bound of the byte size of contract state that is still viewable. None is no limit
 */


data class RpcClientConfigResponse (

    /* Not clear old data, set `true` for archive nodes. */
    @Json(name = "archive")
    val archive: kotlin.Boolean,

    /* Horizon at which instead of fetching block, fetch full state. */
    @Json(name = "block_fetch_horizon")
    val blockFetchHorizon: kotlin.Int,

    /* Behind this horizon header fetch kicks in. */
    @Json(name = "block_header_fetch_horizon")
    val blockHeaderFetchHorizon: kotlin.Int,

    /* Duration to check for producing / skipping block. */
    @Json(name = "block_production_tracking_delay")
    val blockProductionTrackingDelay: kotlin.collections.List<kotlin.Int>,

    /* Time between check to perform catchup. */
    @Json(name = "catchup_step_period")
    val catchupStepPeriod: kotlin.collections.List<kotlin.Int>,

    /* Chain id for status. */
    @Json(name = "chain_id")
    val chainId: kotlin.String,

    /* Time between checking to re-request chunks. */
    @Json(name = "chunk_request_retry_period")
    val chunkRequestRetryPeriod: kotlin.collections.List<kotlin.Int>,

    /* Number of threads for ChunkValidationActor pool. */
    @Json(name = "chunk_validation_threads")
    val chunkValidationThreads: kotlin.Int,

    /* Multiplier for the wait time for all chunks to be received. */
    @Json(name = "chunk_wait_mult")
    val chunkWaitMult: kotlin.collections.List<kotlin.Int>,

    /* Number of threads to execute background migration work in client. */
    @Json(name = "client_background_migration_threads")
    val clientBackgroundMigrationThreads: kotlin.Int,

    /* Time between running doomslug timer. */
    @Json(name = "doomslug_step_period")
    val doomslugStepPeriod: kotlin.collections.List<kotlin.Int>,

    @Json(name = "enable_multiline_logging")
    val enableMultilineLogging: kotlin.Boolean,

    /* Re-export storage layer statistics as prometheus metrics. */
    @Json(name = "enable_statistics_export")
    val enableStatisticsExport: kotlin.Boolean,

    /* Epoch length. */
    @Json(name = "epoch_length")
    val epochLength: kotlin.Int,

    /* Options for epoch sync. */
    @Json(name = "epoch_sync")
    val epochSync: EpochSyncConfig,

    /* Graceful shutdown at expected block height. */
    @Json(name = "expected_shutdown")
    val expectedShutdown: kotlin.String,

    /* Garbage collection configuration. */
    @Json(name = "gc")
    val gc: GCConfig,

    /* Expected increase of header head height per second during header sync */
    @Json(name = "header_sync_expected_height_per_second")
    val headerSyncExpectedHeightPerSecond: kotlin.Int,

    /* How much time to wait after initial header sync */
    @Json(name = "header_sync_initial_timeout")
    val headerSyncInitialTimeout: kotlin.collections.List<kotlin.Int>,

    /* How much time to wait after some progress is made in header sync */
    @Json(name = "header_sync_progress_timeout")
    val headerSyncProgressTimeout: kotlin.collections.List<kotlin.Int>,

    /* How much time to wait before banning a peer in header sync if sync is too slow */
    @Json(name = "header_sync_stall_ban_timeout")
    val headerSyncStallBanTimeout: kotlin.collections.List<kotlin.Int>,

    /* Period between logging summary information. */
    @Json(name = "log_summary_period")
    val logSummaryPeriod: kotlin.collections.List<kotlin.Int>,

    /* Enable coloring of the logs */
    @Json(name = "log_summary_style")
    val logSummaryStyle: LogSummaryStyle,

    /* Maximum wait for approvals before producing block. */
    @Json(name = "max_block_production_delay")
    val maxBlockProductionDelay: kotlin.collections.List<kotlin.Int>,

    /* Maximum duration before skipping given height. */
    @Json(name = "max_block_wait_delay")
    val maxBlockWaitDelay: kotlin.collections.List<kotlin.Int>,

    /* Minimum duration before producing block. */
    @Json(name = "min_block_production_delay")
    val minBlockProductionDelay: kotlin.collections.List<kotlin.Int>,

    /* Minimum number of peers to start syncing. */
    @Json(name = "min_num_peers")
    val minNumPeers: kotlin.Int,

    /* Number of block producer seats */
    @Json(name = "num_block_producer_seats")
    val numBlockProducerSeats: kotlin.Int,

    /* Maximum size of state witnesses in the OrphanStateWitnessPool.  We keep only orphan witnesses which are smaller than this size. This limits the maximum memory usage of OrphanStateWitnessPool. */
    @Json(name = "orphan_state_witness_max_size")
    val orphanStateWitnessMaxSize: kotlin.Int,

    /* OrphanStateWitnessPool keeps instances of ChunkStateWitness which can't be processed because the previous block isn't available. The witnesses wait in the pool until the required block appears. This variable controls how many witnesses can be stored in the pool. */
    @Json(name = "orphan_state_witness_pool_size")
    val orphanStateWitnessPoolSize: kotlin.Int,

    /* Limit the time of adding transactions to a chunk. A node produces a chunk by adding transactions from the transaction pool until some limit is reached. This time limit ensures that adding transactions won't take longer than the specified duration, which helps to produce the chunk quickly. */
    @Json(name = "produce_chunk_add_transactions_time_limit")
    val produceChunkAddTransactionsTimeLimit: kotlin.String,

    /* Produce empty blocks, use `false` for testing. */
    @Json(name = "produce_empty_blocks")
    val produceEmptyBlocks: kotlin.Boolean,

    /* Determines whether client should exit if the protocol version is not supported for the next or next next epoch. */
    @Json(name = "protocol_version_check")
    val protocolVersionCheck: ProtocolVersionCheckConfig,

    @Json(name = "resharding_config")
    val reshardingConfig: kotlin.String,

    /* Save observed instances of invalid ChunkStateWitness to the database in DBCol::InvalidChunkStateWitnesses. Saving invalid witnesses is useful for analysis and debugging. This option can cause extra load on the database and is not recommended for production use. */
    @Json(name = "save_invalid_witnesses")
    val saveInvalidWitnesses: kotlin.Boolean,

    /* Save observed instances of ChunkStateWitness to the database in DBCol::LatestChunkStateWitnesses. Saving the latest witnesses is useful for analysis and debugging. This option can cause extra load on the database and is not recommended for production use. */
    @Json(name = "save_latest_witnesses")
    val saveLatestWitnesses: kotlin.Boolean,

    /* save_trie_changes should be set to true iff - archive if false - non-archival nodes need trie changes to perform garbage collection - archive is true, cold_store is configured and migration to split_storage is finished - node working in split storage mode needs trie changes in order to do garbage collection on hot. */
    @Json(name = "save_trie_changes")
    val saveTrieChanges: kotlin.Boolean,

    /* Whether to persist transaction outcomes to disk or not. */
    @Json(name = "save_tx_outcomes")
    val saveTxOutcomes: kotlin.Boolean,

    /* Skip waiting for sync (for testing or single node testnet). */
    @Json(name = "skip_sync_wait")
    val skipSyncWait: kotlin.Boolean,

    /* Number of threads for StateRequestActor pool. */
    @Json(name = "state_request_server_threads")
    val stateRequestServerThreads: kotlin.Int,

    /* Number of seconds between state requests for view client. Throttling window for state requests (headers and parts). */
    @Json(name = "state_request_throttle_period")
    val stateRequestThrottlePeriod: kotlin.collections.List<kotlin.Int>,

    /* Maximum number of state requests served per throttle period */
    @Json(name = "state_requests_per_throttle_period")
    val stateRequestsPerThrottlePeriod: kotlin.Int,

    /* Options for syncing state. */
    @Json(name = "state_sync")
    val stateSync: StateSyncConfig,

    /* Whether to use the State Sync mechanism. If disabled, the node will do Block Sync instead of State Sync. */
    @Json(name = "state_sync_enabled")
    val stateSyncEnabled: kotlin.Boolean,

    /* Additional waiting period after a failed request to external storage */
    @Json(name = "state_sync_external_backoff")
    val stateSyncExternalBackoff: kotlin.collections.List<kotlin.Int>,

    /* How long to wait for a response from centralized state sync */
    @Json(name = "state_sync_external_timeout")
    val stateSyncExternalTimeout: kotlin.collections.List<kotlin.Int>,

    /* How long to wait for a response from p2p state sync */
    @Json(name = "state_sync_p2p_timeout")
    val stateSyncP2pTimeout: kotlin.collections.List<kotlin.Int>,

    /* How long to wait after a failed state sync request */
    @Json(name = "state_sync_retry_backoff")
    val stateSyncRetryBackoff: kotlin.collections.List<kotlin.Int>,

    /* How often to check that we are not out of sync. */
    @Json(name = "sync_check_period")
    val syncCheckPeriod: kotlin.collections.List<kotlin.Int>,

    /* Sync height threshold: below this difference in height don't start syncing. */
    @Json(name = "sync_height_threshold")
    val syncHeightThreshold: kotlin.Int,

    /* Maximum number of block requests to send to peers to sync */
    @Json(name = "sync_max_block_requests")
    val syncMaxBlockRequests: kotlin.Int,

    /* While syncing, how long to check for each step. */
    @Json(name = "sync_step_period")
    val syncStepPeriod: kotlin.collections.List<kotlin.Int>,

    @Json(name = "tracked_shards_config")
    val trackedShardsConfig: TrackedShardsConfig,

    @Json(name = "transaction_request_handler_threads")
    val transactionRequestHandlerThreads: kotlin.Int,

    /* Time to persist Accounts Id in the router without removing them. */
    @Json(name = "ttl_account_id_router")
    val ttlAccountIdRouter: kotlin.collections.List<kotlin.Int>,

    /* If the node is not a chunk producer within that many blocks, then route to upcoming chunk producers. */
    @Json(name = "tx_routing_height_horizon")
    val txRoutingHeightHorizon: kotlin.Int,

    /* Version of the binary. */
    @Json(name = "version")
    val version: Version,

    /* Number of threads for ViewClientActor pool. */
    @Json(name = "view_client_threads")
    val viewClientThreads: kotlin.Int,

    @Json(name = "chunk_distribution_network")
    val chunkDistributionNetwork: ChunkDistributionNetworkConfig? = null,

    @Json(name = "cloud_archival_reader")
    val cloudArchivalReader: CloudArchivalReaderConfig? = null,

    @Json(name = "cloud_archival_writer")
    val cloudArchivalWriter: CloudArchivalWriterConfig? = null,

    @Json(name = "max_gas_burnt_view")
    val maxGasBurntView: kotlin.Int? = null,

    /* Listening rpc port for status. */
    @Json(name = "rpc_addr")
    val rpcAddr: kotlin.String? = null,

    /* Limit of the size of per-shard transaction pool measured in bytes. If not set, the size will be unbounded. */
    @Json(name = "transaction_pool_size_limit")
    val transactionPoolSizeLimit: kotlin.Int? = null,

    /* Upper bound of the byte size of contract state that is still viewable. None is no limit */
    @Json(name = "trie_viewer_state_size_limit")
    val trieViewerStateSizeLimit: kotlin.Int? = null

) {


}

